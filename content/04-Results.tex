\section{Results} 
\label{sec:Result}


This section will present the results, in regards to development and evaluation. The part about development will briefly explain how the scenes turned out. The evaluation part will present the test results without any interpretation, just numbers. The interpretation of the test results will come in the next chapter: Discussion. 

\subsection{The Prototype}
The development was halted in mid May, 2019, to make time for the user testing and writing the report. The final version of the prototype can be seen in \href{https://youtu.be/VUHdUxoRH5Y}{this} video\cite{UniVRsity}. It shows how the prototype works, how it looks, and a general look into all its content. For more details the code can be found on \href{https://github.com/Zindre17/UniVRsity}{Github}\cite{Github}. 


\subsubsection{Overworld}
The overworld is the starting point of the game. This scene is just a plain with a wall on top of it, and some hovering text, showing the name of the prototype; ``UniVRsity''. The wall contains buttons for all the courses in the prototype, which is at this point in time only one; ``Algorithms and data structures''. The overworld can be seen in the video and in \autoref{fig:overworld}. Pressing a course button by pointing on it with the laser pointer and pressing the trigger button on the controller will make the game transition to the respective course's course hub. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/Overworld.png}
\caption{The overworld.}
\label{fig:overworld}
\end{figure}


\subsubsection{Course Hub for Algorithms and Data Structures}
The course hub for the algorithms and data structures course is very similar to the overworld scene. It has a wall with buttons for each topic, which will when pressed transition the game to the respective topic's scene, and a button for going back to the overworld scene.  The topics available are ``Data Structures'' and ``Sorting Algorithms''. \autoref{fig:algdathub} show this scene. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/AlgDatHub.png}
\caption{The algorithms and data structures course hub.}
\label{fig:algdathub}
\end{figure}

\subsubsection{Data Structures}
The data structures scene is split into two parts. These are the play mode and the use case mode, and can be seen in \autoref{fig:playstart}, \autoref{fig:playprogress}, \autoref{fig:usecasestart}, and \autoref{fig:usecaseprogress}. This scene starts out in the play mode. In this mode the player can choose between the stack and the queue structures, and then play around with them to get a visual representation of what happens when data is added or removed to the selected structure. The use case mode is where the player is presented with a proper use case where the selected structure is used as a part of the solution to the problem. For both the stack and the queue the use case is an image region growing algorithm.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/PlayStart.png}
\caption{The play mode, before selecting a data structure.}
\label{fig:playstart}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/PlayProgress.png}
\caption{The play mode, after selecting the stack structure and pushing a few elements to it.}
\label{fig:playprogress}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/UseCaseStart.png}
\caption{The initial state of the use case mode.}
\label{fig:usecasestart}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/UseCaseProgress.png}
\caption{The use case mode after having done a few steps.}
\label{fig:usecaseprogress}
\end{figure}


\subsubsection{Sorting Algorithms}
The sorting algorithms scene has kept the design of the previous prototype, with a few alterations. The player is now elevated by standing on a cube, to get a better view of everything in the room, and the demo button is moved from the menu wall to the algorithm panel in front and below the player, because connected things should be physically close to each other. Besides this, the room still has the same shape, and most parts are where they were previously. The content in this scene is expanded by adding more algorithms and actions, and text to explain the actions on the wall next to them . The scene can be seen in different states in \autoref{fig:sortingstart} and \autoref{fig:sortingselected}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/SortingStart.png}
\caption{The initial state of the sorting algorithm scene.}
\label{fig:sortingstart}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, totalheight=0.4\textheight, keepaspectratio=true]{images/SortingSelected.png}
\caption{The sorting algorithm scene, having selected the bubble sort algorithm and one of the array elements. Blue/turquoise elements or arrays are selected, yellow are not selected/normal, and green means that the element in this position has the value/size it should have when the sorting is complete.}
\label{fig:sortingselected}
\end{figure}


\subsection{Evaluation}

The user testing was performed in mid May, and 9 people participated. As planned, the participants were given a short description of the game and its intentions to give them some context. They were also informed that they may ask questions if they get stuck, but refrain from doing this needlessly. After the explanation they were asked to equip the VR headset hand the controller, and play the game(user test). Then they played until they felt that they had explored everything, or until they felt they had seen enough. Finally they were asked to fill out a google form. And during the last step some of the participants gave some oral feedback as well. This was all according to the plan presented in the method section. 

\subsubsection{Participants}
Let us see who the participants were. According to their answers in the google form, all of them were students, and all but one had previously taken the course ``Algorithms and data structures''. The majority of the participants had tried VR earlier, but were not very experienced with it. The details can be seen in \autoref{fig:student}, \autoref{fig:VRExp} and \autoref{fig:AlgDat}. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/Student.png}
\caption{The share of the participants currently being students.}
\label{fig:student}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/VRExp.png}
\caption{The amount of experience the participants had with using VR, prior to the user testing.}
\label{fig:VRExp}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/AlgDat.png}
\caption{The relation between the participants and the course ``Algorithms and data structures''.}
\label{fig:AlgDat}
\end{figure}

\subsubsection{Usability}
The results of the SUS gave an average score of 70.3. The average SUS score in general is 68, which means that the usability of this prototype scored above average. The participant which had not taken the course in the prototype gave a score of 85 which is the next highest score given. Only including the participants which had taken the course, made the average score drop to 68.4, which is only slightly above average. This is the almost the opposite result of the testing in the previous project. In that project the lowest score came from the participants not having taken the course, and the average rose when excluding these. 

\subsubsection{Discomfort}
VR is infamous for its tendency to cause motion sickness in players, and some of the participants said they were experiencing this during the user testing. In fact three out of the nine participants said that they felt some degree of motion sickness, which is 33.3\%. Some participants also felt other discomforts such as the game making them feel dumb, or due to other reasons. The details can be seen in \autoref{fig:discomfort}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/VRNegativeEmotion.png}
\caption{The response from the participants in regards to negative emotions felt during the user testing.}
\label{fig:discomfort}
\end{figure}

\subsubsection{Thoughts and General Feedback}
The thoughts of the participants in regards to using VR for teaching/learning were very positive, and their experience with the prototype was for the majority good. In fact everyone thought that VR in general could be useful for learning! Almost all thought that an application like the prototype also could be useful. The answers can be seen in \autoref{fig:enjoy}, \autoref{fig:useful} and \autoref{fig:generalUseful}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/VREnjoy.png}
\caption{Whether or not the participants enjoyed the experience of playing ``UniVRsity''.}
\label{fig:enjoy}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/VRThisUseful.png}
\caption{Whether or not the participants thought that ``UniVRsity'' could be useful for teaching/learning.}
\label{fig:useful}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/VRGeneralUseful.png}
\caption{Whether or not the participants thought VR could be useful for teaching/learning in general.}
\label{fig:generalUseful}
\end{figure}

The general feedback given was that it was not clear that the user could do the steps in the algorithms manually. Most only used the ``Demo'' or ``Do next step'' buttons when playing the game. Some also said that a lot of things happened simultaneously and it was hard to know where to focus, specifically for the use case in the data structures scene.  



