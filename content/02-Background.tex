% Teori om teknologi, læring, software osv.
\section{Background}

This section will provide background information about the technologies and software utilized in this project, as well as theory addressing learning, learning with multimedia, and enjoyment in games. It will build the foundation for the planning and design choices made in this project. 

\subsection{Virtual Reality}
\todo{add images of second gen}

Virtual reality(VR) has many definitions, but in the context of this project VR refers to a virtual environment with spatial and orientation tracking of a head mounted display(HMD) and controllers. In VR the virtual environment's visuals are 100\% computer graphics, while the interaction with these generated visuals are done through the movement of the physical body of the user. VR is also a part of the term XR, or Cross Reality, which includes VR, mixed reality(MR), augmented reality(AR), and a few more. Most of these use a mixture of the real world and graphics in the visuals, which contrasts to VR's 100\% graphical visuals.

The HTC Vive(figure \ref{fig:htcvive}) and the Oculus Rift(figure \ref{fig:oculus}) are the first generation of consumer VR-kits and are also currently the standard. This first generation of VR devices first hit the consumer market in 2016, but development kits and prototypes have been available a lot longer. The second generation of VR is already announced, some even available for pre-order, and the thing about these seems to be the lack of external sensors for tracking the headset and controllers. They are now integrated in the HMD. This will make transportation and setting up a lot easier. The user experience should also be better as this should remove the dizzying and or nauseating effect when the sensors loose track of the headset. They also boast better visuals in terms of less "screen door"-effect, higher resolutions, better colors, and some even eye-tracking. Both HTC and Oculus has announced tether-less versions for gaming as well. The previous generation's tether-less version were not compatible with games, as they did not support controllers suitable for this purpose.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/Htcvive.jpg}
\caption{HTC Vive Pro and controllers}
\label{fig:htcvive}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/oculusrift.png}
\caption{Oculus Rift and Touch controllers}
\label{fig:oculus}
\end{figure}
%The exact origins of virtual reality is uncertain due to the difficulty of defining an alternative existence. Then what is virtual reality? In terms of functionality it is a simulation where the world one sees is computer generated graphics which responds to input from the user in real-time. %[https://books.google.no/books?hl=no&lr=&id=0xWgPZbcz4AC&oi=fnd&pg=PR13&dq=virtual+reality+origin&ots=LDgAgW0Ncw&sig=gG7pQ1B9dXtZTtHGqBuIAyWE3uw&redir_esc=y#v=onepage&q=virtual%20reality%20origin&f=false ].
%Virtual reality environments exist in several different forms. Some use projectors and rooms, while others use head mounted displays, or HMDs, and controllers. In recent times, HMDs have seen a surge in popularity and interest, most likely due to the increase in hardware capacity and decrease in size and price. Within this group or form of VR, there are kind of two categories. Due to the fact that technology has evolved to where it is now, even some smart phones are able to power light virtual reality experiences. This is the first category which uses regular smart phones or dedicated standalone headsets with equivalent specifications to power the virtual reality experience. These are experiences are limited in functionality and power due to the size. The second category are headsets and controllers which are powered by an external computer. This allows for far more computationally heavy applications. I will develop for the second category, since this allows the use of controllers and more complex interaction for better immersion. 

\subsection{Software}

Unity and Unreal Engine 4 were the only game engines considered for developing this application. They are the most common engines for independent developers to chose, especially for VR development. Both are also free to use for non-commercial use, and mostly free for commercial use as well, with a few limitations and or exceptions. This makes these engines ideal for beginners just starting out or wanting to test game development. One of the major differences in these engines is the lighting. In Unity the lighting is baked, while in Unreal it is not. This gives Unreal the edge when realistic graphics is wanted. Unreal also focuses more on 3D games giving them the advantage there. On the other hand, this gives Unity the edge in 2D games. They also use different programming languages.
%The biggest difference in these engines is the lighting. In Unity the lighting is baked, while it is not in Unreal, which gives Unreal a more realistic look by default. The trade-off for better more realistic lighting is that it is more work to develop in this engine? %todo check if this is the case
\subsubsection{Unity}
Unity has support for several languages, but the two most used are C\# and Javascript. To such an extent that Unity is dropping/has dropped support for other languages. Unity is based around game objects and scripts, or components, attached to these game objects. These components, if they inherit from the default unity class: MonoBehaviour, have a start function which is run at the time the object is created, and an update function which is run every frame. MonoBehavior also has access to many more functions, but these are the basics. Unity is a mixture of visually programming and coding. If a variable in Unity is marked as public, it can be accessed visually within the editor. Unity also has an Asset store within the editor where all sorts of assets, like models, textures, sounds, and visual effects, can be purchased or downloaded for free. These assets are made by the community, and the quality is therefore varying, but there is a rating system to help chose wisely.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/unit3d.png}
\caption{Unity logo}
\label{fig:unity}
\end{figure}

\subsubsection{Unreal Engine}
Unreal Engine uses C++ for development. However, it also provides "blueprints" which is an interface for scripting visually(drag n' drop). Strictly speaking, this means that both Unreal Engine and Unity can create games without having to code. Unreal is based around actors, which are almost equivalent of game objects in unity. Actors have components just like game objects in unity has. In addition they can have blueprints or scripts attached to them.  %todo lære litt unreal for å snakke litt om det

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{images/unreal.png}
\caption{Unreal Engine logo}
\label{fig:unreal}
\end{figure}

\subsubsection{SteamVR plugin}
Since there exist many different forms of controllers and HMDs, Valve has created a plugin for Unity and Unreal Engine, SteamVR plugin\cite{SteamVRPlugin}. This plugin makes it possible to support a wide variety of devices using the same code. Using this will minimize the code needed to support a wide variety of devices. The difference between a VR game and a normal 3D game is that VR games need to somehow reflect the users movements and actions in real life within the game. I.g move the hands to where the user moves their controllers, look in the direction the user is pointing their head, and all these things. The focus of this plugin is therefore to make the camera follow the users head, load models of the controllers in use, make these controller models follow the users hands, handle the inputs of these, and estimate how the users hands look while using these controllers.



%Teaching

%Regular classroom teaching has its flaws and advantages. One of the biggest flaws is probably that it tries to teach a whole group at the same time. Because the teacher - student relation is one(few) to many, the entire group will necessarily be taught with the same pace. This is where classical method of teaching fails. Everyone learns at their own pace, and therefore some will get “left behind” while others will get bored. %A virtual single player game can fix this issue by allowing each user to progress at their own pace by enabling functionality such as skip or rewind. However, this comes at the cost of eliminating communication.  

%Learning is enhanced when the learner is more immersed. This is quite obvious since learning requires focus, and immersion is, in a sense, a measurement of focus. A student who is more eager to answer or ask questions, or active, is a more immersed student, and is therefore more likely to learn more. Computers have gradually and increasingly been introduced as a supplement in the traditional classroom teaching method in recent years, as an attempt to improve teaching. Even though a computer requires interaction, which sort of forces at least a certain level of focus, it is easy to get distracted by what is happening around you. The belief here is that VR will be far superior to an ordinary computer screen in inducing immersion, since wearing a VR-headset blocks off your vision and partially your hearing.   



\subsection{Multimedia Learning Theories}

The cognitive theory of multimedia\cite{Mayer2014}, which is based upon the cognitive load theory\cite{CognitiveLoadTheory}, states that the visual input and the auditory input are processed on different channels, with a limited cognitive capacity for processing these inputs. This means if the visual channel is overloaded with input, the auditory channels processing will suffer, and vice versa. From this follows that irrelevant images, sounds, or words can harm the learning in the learner, and should therefor be avoided. In the book Multimedia learning\cite{Mayer2009}, Mayers present twelve principles for better design when using multimedia for presenting material. These principles are backed by both the cognitive theory of multimedia, and empirical studies.

The principles are as follows: 
\begin{itemize}
    \item Coherence Principle - People learn better when extraneous words, pictures and sounds are excluded rather than included.
    \item Signaling Principle - People learn better when cues that highlight the organization of the essential material are added. 
    \item Redundancy Principle - People learn better form graphics and narration than from graphics, narration and on-screen text.
    \item Spatial Contiguity Principle - People learn better when corresponding words and picture are presented near rather than far from each other on the page or screen.
    \item Temporal Contiguity Principle - People learn better when corresponding words and pictures are presented simultaneously rather than successively. 
    \item Segmenting Principle - People learn better from a multimedia lesson is presented in user-paced segments rather than as a continuous unit.
    \item Pre-training Principle - People learn better from a multimedia lesson when they know the names and characteristics of the main concepts.
    \item Modality Principle - People learn better from graphics and narrations than from animation and on-screen text.
    \item Multimedia Principle - People learn better from words and pictures than from words alone.
    \item Personalization Principle - People learn better from multimedia lessons when words are in conversational style rather than formal style.
    \item Voice Principle - People learn better when the narration in multimedia lessons is spoken in a friendly human voice rather than a machine voice.
    \item Image Principle - People do not learn better from a multimedia lesson when the speaker's image is added to the screen.
\end{itemize}

%All these principles are important to consider, and the ones I deemed the most important are the coherence principle, the redundancy principle, the modality principle, the personalization principle, and the voice principle. 
The fact that VR gives the opportunity to do anything or be anywhere, has the potential to unintentionally be very distracting if the environment is very detailed  and or dynamic, as this can draw the attention away from the presented material the user is supposed to interact with and learn from. However, always keeping the coherence principle in mind, and thinking twice when adding content of whether it is an aid in the learning process or not, can help in avoiding such a situation. An interesting environment will probably pique a users interest initially but might be distracting and decrease the efficiency and effectiveness of the learning material. There seems to be a trade-off there, unless the environment changes into something less distracting when the application requires the users attention elsewhere. 
%According to the coherence principle, people learn more or better if there are no irrelevant information or distractions. This can be anything from sound effects or animations in power point slide transitions, to digressions, to irrelevant imagery. I think this point in particular is important to take note of. VR gives the opportunity to do anything or be anywhere, which means it could be easy to fall for the temptation of creating a really interesting environment. This will probably pique the users interest, but might end up harming the application in terms of learning, if it distracts attentions away from the material presented.

When it comes to deciding how to design the instructions, the redundancy principle suggests it has graphics and narration, but without text. The reasoning lies with the redundant text prompting extra visual processing, resulting in less learned. And while in the area, the modality principle suggests that instructions should consist of graphics and voice, rather than graphics and text. By having both text and graphics the visual channel might get overloaded, while with graphics and voice, the input is split among the auditory and visual channels.

Taking the pre-training principle into consideration, it would suggest that having this prototype as an addition to lectures or other classic teaching methods, rather than as a stand-alone product, is more effective. The reason for this is that knowing some of the terms and characteristics of a concept in advance means that the user has kind of allocated a space in his/her knowledge space where the new information can go. An analogy might be a cake. A cake can be eaten without knowing the ingredients or how it is made. However, presented with only the ingredients and it is very hard to imagine what they become when combined in a specific way.

One of the principals that the masters degree project of Kong and Kruke\cite{KongOgKruke} followed well, is the segmentation principle. The prototype allows the players to control the pace of the learning to a high degree. The players can choose which sorting algorithm to learn, and they can do it step by step with as much time as they need per step. This is something to keep in mind for this project too. 
%Since the goal of this project is not to replace the existing teaching method, but be an addition to it. The pre-training principle says that this is advantageous, as a learner who already knows the names and characteristics of the main concepts will learn more deeply from a multimedia instruction. If we take a look at the masters degree report of Kong and Kruke\cite{KongOgKruke}, they organized their game into single algorithms which enables the player to control the pacing of the information, to a certain degree. This is what the segmentation principle suggests, and is therefore to be considered in this project as well. 

Lastly from these principles it is worth noting that people learn better when words are in conversational style rather than formal style, because the learner will be prompted to try harder when they feel that someone is talking to them specifically. Also, if these words are in the form of voice rather than text, the learner will be more engaged if the voice is human and kind compared to robotic and cold. This is according to the personalization and voice principles. 

\subsection{Video Games and Fun}

Even though this project is based around an educational game, it is still a game, and games are inherently made to be fun or entertaining. This is something which should, therefore, also be considered in this project. In 2005, Penelope Sweetster and Peta Wyeth, made an attempt at creating a model for evaluating and designing fun games. This model was based on Csikszentmihalyi's Flow theory\cite{Flow}, which is a theory or model on enjoyment in general, and the adapted version was named, creatively so, GameFlow\cite{GameFlow}. 

GameFlow consists of eight elements; Concentration, Challenge, Player Skills, Control, Clear Goals, Feedback, Immersion, and Social Interaction. For someone to enjoy a game, all of these elements does not necessarily need to be fulfilled, but at least a few of them. As an example, a game can be fun even though it does not include social interaction. Anyways, let's review what lies within these elements. 

\begin{itemize}
    \item Concentration - Games should require concentration, but also help the player in doing so
    \item Challenge - Games should be sufficiently challenging
    \item Player skills - Games should support player skill development and mastery
    \item Control - Players should feel that they are in control of their actions in the game.
    \item Clear goals - Games should provide players with clear goals at appropriate times
    \item Feedback - Players should receive appropriate feedback at appropriate times
    \item Immersion - Players should experience deep but effortless involvement in the game
    \item Social Interaction - Games should support and create opportunities for social interaction
\end{itemize}

%These eight points might prove helpful when making design choices for the prototype

Using VR will surround the entire field of vision for the player and should in theory increase the users attention towards the VR application. However, it is still not guaranteed that the player will aim its attention within the virtual world to the place where the developer intended for the player to have their focus. It will only guarantee that the attentions is somewhere within the virtual world. Immersion is closely linked to concentration and is another point where using VR as a platform might be beneficial. The selling point for VR is the immersion that it gives and strives to get even better at. This suggests that there is less need to focus on designing the game in such a way that it promotes immersion, since the VR platform does a lot of work for this point by just being this platform. The other points will probably not gain too much just from the prototype being in VR. Nevertheless, all eight points should be taken kept in mind when designing the prototype.




\subsection{Four Keys to Fun}

Lazzaro found that there are four ways to make player have fun and enjoy games\cite{lazzaro}. This is merely an identification of where the fun comes from, and does not directly provide a tool for better game design. However, knowing what can make a game fun might prove helpful anyways. It can also be used to analyze existing game design, even though it will not provide suggestions for improvements.

The four keys are as follows:
\begin{itemize}
    \item Hard Fun (Fiero)
    \item Easy Fun 
    \item Serious Fun
    \item People Fun
\end{itemize}

Hard fun is, as its name implies, when the fun comes from the difficulty within the game. If something is difficult and the player fails, they will feel frustration, and as they keep failing, their frustration will increase. However, if the player gets a tiny bit better every time, the player will eventually complete the challenge, and when that moment comes, all of the frustration goes away in an intense emotion referred to as "fiero", and after the excitement of finally having completed the challenge, the player feels relieved... until the next challenge is at hand, and the process repeats. It should be noted that there exists different kinds of frustration and not all of them will lead to the player having fun. 

Easy fun comes from curiosity. If the game inspires curiosity the player will enjoy the game. Having freedom in the interaction can help in this regard, as the player might then be tempted to explore the boundaries of what is possible to do. The chain of emotion in this key of fun is: Curiosity - Surprise - Wonder or Awe - Relief - Back to curiosity again. Put into a scenario: A player is curious as to what happens when he does a certain kind of action, the result of the action performed was not expected in the player and is surprised. After the initial surprise the player is in wonder by this result and feels relieved as the itch from the curiosity is now gone. Then it repeats when the player pops up with a new question he or she wants answered. However, for this to be effective, the results of the exploration and fooling around need to be balanced between novelty and familiarity; too novel - and the player falls into disbelief, too predictable - and the player is bored or lose interest.

Serious fun comes when the player is playing to change how he or she thinks, behave, or to accomplish real work. This means that serious fun is very subjective. If a game is low on serious fun, it will feel like a waste of time. And the emotions linked to serious fun usually comes from the graphics, sound, and or atmosphere within the game. It can also be a more cognitive fun as it might give players something to think about outside of the game.

People fun has to do with everything which connects the game with other people. This can be by talking about the game with your friends face to face, by having a chat in-game, or what have you. Interacting with other people is an important source for feeling different emotions. It can also create identities and shape relationships. 

The more a game applies these four key, the more entertaining it will be. And a fun game is a more effective one. Therefor these keys should be kept in mind both when designing the prototype, and during the testing. 

\subsection{System Usability Scale}
The System Usability Scale\cite{SUS}, or SUS for short, is a way for measuring usability in a system, be it hardware or software. It consists of a questionnaire with 10 fixed statements where the responses to these should be on a scale from 0 to 4, where 0 equals "Strongly disagree" and 4 being "Strongly agree". The creator of this measuring tool is John Brooke, in the year 1986. SUS has become the industry standard due to its simplicity for the participants, and the fact that it does not need a large sample size to get reliable results. The following 10 items are the fixed statements of a SUS questionnaire:
\begin{itemize}
    \item I think that I would like to use this system frequently.
    \item I found the system unnecessarily complex.
    \item I thought the system was easy to use.
    \item I think that I would need the support of a technical person to be able to use this system.
    \item I found the various functions in this system were well integrated.
    \item I thought there was too much inconsistency in this system.
    \item I would imagine that most people would learn to use this system very quickly.
    \item I found the system very cumbersome to use.
    \item I felt very confident using the system.
    \item I needed to learn a lot of things before I could get going with this system.
\end{itemize}

Scoring the response of the SUS questionnaire follows these steps\cite{MeasuringSUS}:
\begin{itemize}
    \item Odd items: add the score to the cumulative score
    \item Even items: flip the score then add to the cumulative score(subtract given score from 4. In other words if a participant gives 1 as a response on a question then the flipped score will be 4 - 1 = 3)
    \item finally after summing all scores, multiply by 2.5 to increase the score range from 0-40 to 0-100
\end{itemize}

As the scores of a SUS is between 0 and 100 it can be tempting to look as these as a percentage. This is, however, the wrong way to interpret the scores. The average SUS score is 68 and is therefor in the percentile rank of 50\%. The percentile rank increases quite rapidly from there and is in the percentile rank of 70\% already at a score of 74, and percentile rank of 90\%(top 10\%) at a score of 80.4. Below the 68 score the percentile rank drops to 30\% at about 60, and to 10\% at about 47. In other words the percentile rank drops really fast close to the average score, and a bit less so further away from it. A score of 67 and 69 is therefore quite far apart from each other in terms of the percentile rank.  

The System Usability Scale was used in the previous project as the next section will give some more information about. It should probably also be used in this project, as it is very easy to use for the participants, and it gives a good indication as to whether or not the application is user friendly.

\subsection{Previous Work}

As already stated, this project is a continuation of another project. The prototype developed in that project consisted of a single scene, which was for teaching sorting algorithms. This scene had implemented two sorting algorithms: bubble sort and insertion sort. \href{https://youtu.be/7m7B7zJ4KIQ}{Click here} to see a video of the functionality and contents of the first prototype. The interaction was purely through pointing with a laser in the right hand and pressing the trigger when pointing at objects which were interactive. This prototype was also user tested, though only by 5 people. The user test consisted mainly of a usability test, utilizing the System Usability Scale. What the results of this testing showed was that usability was closely linked with the whether the player had taken the course or not. 

\subsubsection{Design}
As can be seen in video of the previous prototype, the design of the scene where the sorting happens is formed kind of like a semi circle. To the front, the representation of the array is shown, with the array elements represented as yellow cuboids with height visually representing their value, and the array itself represented as a cuboid laying on the ground with its elements hovering above it. To the left of the array, still to the front, lies a cube representing the storage area, where algorithms needing to save values outside of the array can place them. On the floor in front of where the player stands, there is a panel. This panel shows the state of the algorithm, the pseudo code for the algorithm, and shows output from the most recent comparison of elements. To the left are two walls with buttons aligned vertically. One for selecting algorithm, and one with buttons for starting a demonstration of the algorithm, starting the algorithm over again, and getting a new randomly generated array. The buttons are thin cuboids with big labels on them representing their respective actions. The other side, to the right, contains a wall with action buttons. The available actions are compare, swap, store, and copy to.

Reading a value as a number in text is easy, Seeing the value as the length of an object is easier. That is the reasoning behind the design of the array elements. The two projects from the year before mainly used cubes of equal size, though an option to show the difference in size as one shrinking and one growing was available in one of them. The reason for choosing equal sized cubes in their prototypes are most likely grounded in their choice of interaction. They represented arrays as cubes, and the player had to do the physical motion of picking up the cubes to sort them. Picking up big objects is more awkward than using hand-sized objects, and is probably their reason for their design choice. However, my design uses a laser pointer for interaction, and there is no more an issue of awkwardly picking up large objects. Using a laser pointer opens up a lot of new options compared to what the other prototypes had, and loses some opportunities in comparison also. One of the reasons behind choosing a laser pointer as interaction mechanism, was that it removes a lot of the distraction involved with having the ability to play around with stuff with virtual hands. Just having hands seem to distract people who has not tried VR before as they are amazed by the feeling of seeing their own hands move in the virtual world. And as the theory presented the previous chapter suggests, distractions are bad when it comes to learning.

\subsubsection{Development}
The chosen game engine in the previous project was Unity, because it felt easier and quicker to use after some tinkering about in both Unity and Unreal. Research into which engine to choose for the project did not really lead anywhere, and suggested it should just be up to personal preference. Seeing as I was not particularly determined to make a realistic looking game, there was no need for the non-baked lighting which Unreal provides.

After the decision of which game engine to use, it had to be properly learned. This was done through a combination of watching youtube videos, reading the documentation, doing tutorials, and experimenting. The main channels used were \href{https://www.youtube.com/channel/UCLO98KHpNx6JwsdnH04l9yQ}{FusedVR} for VR specifics and \href{https://www.youtube.com/user/Brackeys}{Brackeys} for general Unity things. Both of these channels used C\# as their programming language of choice in their videos, and it ended up being the language I chose as well. Youtube videos are great because one can learn how professionals or people with a lot of experience with the engine uses it, and their workflows. They can also be helpful in terms of how to solve common problems or help in avoiding common mistakes beginners do. Before the development of the actual prototype went down, a couple of mini-VR-games were made. This was just to get used to the engine, and also how to interface with the VR gear. This experimentation proved to be very effective as it gives hands on experience and a sense of how to work with this technology. 

To be able to use any VR-kit without writing hardware specific code, the SteamVR Plugin for Unity was used. To be able to work anywhere, the version control system Git was used, and it is hosted on Github, as a public repository. Hosting the project on GitHub in a public repository will enable other developers to further build upon this project, should it turn out to be a good one. There was no need to use Unity's collaboration tool/version control system, Unity Collaborate\cite{UnityCollab}, as there was only one developer during the extent of this project. 

\subsubsection{Architecture}
The architecture in the previous project, was focused around the game having to be modular, and easily expanded. To do this, sorting algorithms had to be generalized such that the common functionality would not need to be re-implemented, instead only specifics for the new algorithm. The same went for user actions. They were also generalized such that it would be easy to add new actions. This architecture makes it a lot easier to add new algorithms and actions, but it requires more thought into the initial development. The algorithms was generalized fairly well during the development, however, actions, not so much. Due to the way the algorithms were made, they were completely isolated from the arrays them selves, which meant that actions could not be generally designed. The result was actions just having a type, an enum describing what action it represents, and some integer values representing the position within the array the action should affect. This in turn meant that what the different types actions actually do, is up to whichever component is handling the action. The positive with this is that the action types can be reused in other scenes, as they have no actual actions linked to them. However, in this case it probably would have been smarter to not have the sorting algorithms be disconnected from the array representation, and therefor the actions separated from them. 

\subsubsection{Testing}
The testing was quickly brushed over in the introduction of this prototype, saying it was mainly a SUS questionnaire and that 5 people participated. The results of the SUS was a score of 67.5 which is below average. However looking at the background of the testers the scores could indicate that having taken the course in advance was correlated to a higher ease of use. The average score of people having had the course was to 75.83, which is a good score. Just watching the tests also gave a lot of insight. People thought that the prototype was some some sort of playground, where one could also see how some algorithms worked. This was not the case, and it confused the testers. The laser pointer interaction seemed to be intuitive, but how to perform the different actions on the array was not very intuitive. 

\subsubsection{Unfinished ideas}
Some of the features or ideas for the project was not implemented due to time constraints and or other difficulties. The ones worth mentioning are these:
\begin{itemize}
    \item Voice - Add voice which gives instructions instead of/in addition to the text.
    \item Overworld - Add an overworld where the player can travel to different courses.
    \item Tree traversing algorithms - Add a scene where the player could learn different tree traversing algorithms.
    \item Highlight line of code being executed
    \item Tutorial - Add a form of tutorial explicitly teaching the player what they can do.
    \item Remove the gun model - Should be a normal laser pointer instead
\end{itemize}
These ideas should be considered when planning the further development of this prototype in this project. 

\begin{comment}

- cognitive theory of multimedia
- cognitive load theory

- Adding stuff like visual effects, sounds and animations, will "use up" some of the cognitive capacity of the learner on , resulting in less capacity available for learning the material. 

- multimedia learning == learning from words and pictures

- previous studies have found that immersive VR, when not carefully designed, can distract the learner with animations and dynamic environments, from where the focus should be. E.g. spoken words or a demonstration. 

- coherence principle and segmenting principle

- Coherence: people learn better when unnecessary words, sounds, and  pictures are excluded. These divert the attention away from the important stuff, disrupt the process of organizing the information, and may lead to improper integration of new information with existing knowledge in the learner.(Mayer 2009). Research which backs up this theory showed that instructions in desktop VR in 2D was superior to desktop VR in 3D, due to the fact that the 3D environment requires more cognitive processing. Also research has found that cartoon-like graphics outperform photo realism, due to the same fact. 

- Segmenting: people learn better when the lesson is presented in user-directed segments, and not as a continuous unit. This boils down to letting the learner decide the pacing of incoming new information. VR animations are usually continuous and therefore not abiding to this principle, to some extent. 
- These principles shows that VR is very susceptible to not being as effective for teaching. 


- Give the students something to do, not something to learn(learning by doing) - john dewey

- Low-knowledge level learns best from images and speach(with instructions), while High-knowledge level learns best from images(without instructions) alone. 

- Gameflow

\end{comment}